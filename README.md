# Generative AI With Large Language Models

This repository contains detailed code examples for the course [Generative AI With Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms), offered by [DeepLearning.AI](https://www.deeplearning.ai/) on [Coursera](https://www.coursera.org/).

## Structure

The repository contains 4 folders:

- [`code`](./code) - Contains two coding assignments:
  - [`Fine-Tuning Lab.ipynb`](./code/Fine-Tuning%20Lab.ipynb) - Assignment which covers Instruction Fine-Tuning using LoRA.
  - [`RLHF Lab.ipynb`](./code/RLHF%20Lab.ipynb) - Assignment which covers using Reinforcement Learning From Human Feedback to align LLMs.
- [`Week 1`](./Week%201/):
  - [`Transformers`](./Week%201/Transformers.pdf) - Basics of Transformers.
  - [`Prompting and Prompt Engineering`](./Week%201/Prompting%20and%20Prompt%20Engineering.pdf) - Basics of prompting, prompt engineering and inference configuration parameters (temperature, etc).
  - [`Pre-training Large Language Models`](./Week%201/Pre-training%20Large%20Language%20Models.pdf) - Basics of how LLMs are pre-trained.
  - [`Efficient Multi-GPU Compute Strategies`](./Week%201/Efficient%20Multi-GPU%20Compute%20Strategies.pdf) - Approaches available for training LLMs in a distributed manner.
- [`Week 2`](./Week%202):
  - [`Instruction Fine-Tuning`](./Week%202/Instruction%20Fine-Tuning.pdf) - Basics of fine-tuning LLMs.
  - [`Model Evaluation - Metrics and Benchmarks`](./Week%202/Model%20Evaluation%20-%20Metrics%20and%20Benchmarks.pdf) - Details on evaluation metrics and benchmarks for LLMs.
  - [`Parameter Efficient Fine Tuning (PEFT)`](./Week%202/Parameter%20Efficient%20Fine-Tuning%20(PEFT).pdf) - Basics of PEFT, covering LoRA and Soft Prompts.
- [`Week 3`](./Week%203):
  - [`Reinforcement Learning From Human Feedback (RLHF)`](./Week%203/Reinforcement%20Learning%20From%20Human%20Feedback%20(RLHF).pdf) - Basics of RLHF.
- [`markdown`](./markdown/) - Contains the same files as above except in Markdown format for those who prefer to read directly on GitHub.
